{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from mapsgan import TrajectoryDataset\n",
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How depends the shape of hidden on the batchsize in LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "input_size = 4\n",
    "hidden_size = 7\n",
    "batch_size =  5\n",
    "sequence_length = 12\n",
    "num_layers =  2\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers) # input_sze, hidden_size, batch_first\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(sequence_length, batch_size, input_size) # batch_size, seq_len, input_size\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.view(-1, num_classes) # num_classes is 5\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(num_layers, batch_size, hidden_size),\n",
    "                torch.zeros(num_layers, batch_size, hidden_size))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "input = torch.rand(sequence_length, batch_size, input_size)\n",
    "hidden = model.init_hidden()\n",
    "out, hidden = model(input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape #(num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example\n",
    "Predict ihello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'hihello'\n",
    "letters = np.unique([x for x in word])\n",
    "lookup = {let:num for num, let in enumerate(letters)}\n",
    "idx2char = {num:let for num, let in enumerate(letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = {l:np.zeros(letters.size) for l in letters}\n",
    "for i, (letter,val) in enumerate(vec.items()):\n",
    "    vec[letter][i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': 0, 'h': 1, 'i': 2, 'l': 3, 'o': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'hihell'\n",
    "x_onehot = torch.Tensor([[vec[let] for let in x]])\n",
    "y = 'ihello'\n",
    "labels = torch.Tensor([[lookup[l]] for l in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_onehot = torch.cat([x_onehot, torch.zeros_like(x_onehot)], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.cat([labels, torch.zeros_like(labels)-1], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 3.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes, input_size, hidden_size, batch_size, sequence_length, num_layers = 5, 5, 5, 1, 12, 1\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True) # input_sze, hidden_size, batch_first\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(batch_size, sequence_length, input_size) # batch_size, seq_len, input_size\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.view(-1, num_classes) # num_classes is 5\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = model(x_onehot, model.init_hidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7530, -0.1349,  0.2548,  0.2163,  0.4934]]], grad_fn=<ViewBackward>),\n",
       " tensor([[ 0.4792,  0.0799,  0.6758,  0.3247,  0.7181],\n",
       "         [ 0.7376, -0.1749,  0.5956,  0.3965,  0.5270],\n",
       "         [ 0.3284, -0.2711,  0.5929,  0.6146,  0.5298],\n",
       "         [ 0.5054,  0.0884,  0.7353, -0.0268,  0.2535],\n",
       "         [ 0.6318, -0.0575,  0.1240,  0.2851,  0.4715],\n",
       "         [ 0.7530, -0.1349,  0.2548,  0.2163,  0.4934]],\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model(x_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch-cpu_1532578932944/work/aten/src/THNN/generic/ClassNLLCriterion.c:93",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-361-b8e2e5bac93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print([idx2char(int(torch.max(hid, 1)[1])] for hid in hidden])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     for input, label in zip(x_onehot, labels):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mapsgan/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mapsgan/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 862\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mapsgan/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mapsgan/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1405\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch-cpu_1532578932944/work/aten/src/THNN/generic/ClassNLLCriterion.c:93"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first = True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optim.zero_grad()\n",
    "    loss = 0\n",
    "    output, hidden = model(x_onehot, hidden)\n",
    "    output = output.view(sequence_length, -1)\n",
    "    #print([idx2char(int(torch.max(hid, 1)[1])] for hid in hidden])\n",
    "    loss += criterion(output, labels.squeeze().long())\n",
    "    \n",
    "#     for input, label in zip(x_onehot, labels):\n",
    "#         hidden, output = model(input, hidden)\n",
    "#         _, pred = torch.max(output, 1)\n",
    "#         print(idx2char[int(pred)])\n",
    "#         loss  += criterion(output, label.long())\n",
    "        \n",
    "    print(\"epoch: %d, loss: %1.3f\"%(epoch+1, loss.data[0]))\n",
    "    loss.backward(retain_graph=True)\n",
    "    optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['e', 'h', 'e', 'l', 'l', 'o', 'e', 'e', 'e', 'e', 'e', 'e'],\n",
       " ['i', 'h', 'e', 'l', 'l', 'o', 'e', 'e', 'e', 'e', 'e', 'e'])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2char[int(torch.argmax(l, dim = 0))] for l in output], [idx2char[int(l)] for l in labels.squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "loss =  1.5305711030960083\n",
      "['i', 'h', 'i', 'o', 'o', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  10\n",
      "loss =  1.5292962789535522\n",
      "['h', 'o', 'h', 'l', 'o', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  20\n",
      "loss =  1.332958459854126\n",
      "['i', 'h', 'i', 'l', 'o', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  30\n",
      "loss =  1.1438624858856201\n",
      "['i', 'h', 'e', 'l', 'l', 'l']\n",
      "---------------------\n",
      "\n",
      "epoch =  40\n",
      "loss =  0.9774511456489563\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  50\n",
      "loss =  0.8569862842559814\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  60\n",
      "loss =  0.775343120098114\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  70\n",
      "loss =  0.7400549054145813\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  80\n",
      "loss =  0.8040781617164612\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  90\n",
      "loss =  0.8265789151191711\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  100\n",
      "loss =  0.8235683441162109\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  110\n",
      "loss =  0.8131890296936035\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  120\n",
      "loss =  0.8021772503852844\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  130\n",
      "loss =  0.7922517657279968\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  140\n",
      "loss =  0.7835415005683899\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  150\n",
      "loss =  0.7758567929267883\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  160\n",
      "loss =  0.7690275311470032\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  170\n",
      "loss =  0.7629514336585999\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  180\n",
      "loss =  0.757575273513794\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  190\n",
      "loss =  0.7528679966926575\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  200\n",
      "loss =  0.7487962245941162\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  210\n",
      "loss =  0.7453052997589111\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  220\n",
      "loss =  0.7423131465911865\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  230\n",
      "loss =  0.7397163510322571\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n",
      "epoch =  240\n",
      "loss =  0.7374066710472107\n",
      "['i', 'h', 'e', 'l', 'l', 'o']\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Number of seq_len is len(example)-1 == time steps\n",
    "seq_len = 6 # |hihell|==6\n",
    "# Number of batches\n",
    "batch_size = 1\n",
    "# Number of features\n",
    "input_size = 5 \n",
    "# Hidden size, output size\n",
    "hidden_size = 5   \n",
    "# Number of layers\n",
    "num_layer=1\n",
    "# One hot encoding for each char in 'h','i','e','l','o'\n",
    "h = [1, 0, 0, 0, 0]\n",
    "i = [0, 1, 0, 0, 0]\n",
    "e = [0, 0, 1, 0, 0]\n",
    "l = [0, 0, 0, 1, 0]\n",
    "o = [0, 0, 0, 0, 1]\n",
    "\n",
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "# Teach hihell -> ihello\n",
    "\n",
    "# The input need to match this format: (seg_len, batch_size, input_size)\n",
    "input = torch.tensor([h, i, h, e, l, l], dtype = torch.float)\n",
    "input = input.view(seq_len, batch_size, input_size)\n",
    "\n",
    "# Same with target (1, batch_size, hidden_size)\n",
    "y_data = [1, 0, 2, 3, 3, 4]    # ihello\n",
    "target = torch.tensor(y_data)\n",
    "#print(input.size(), target.size())\n",
    "\n",
    "# Create random hidden state\n",
    "state = torch.randn(num_layer, batch_size, hidden_size)\n",
    "\n",
    "# Create RNN \n",
    "rnn = nn.RNN(input_size=input_size, \n",
    "             hidden_size=hidden_size, \n",
    "             num_layers=1, \n",
    "             nonlinearity='tanh')\n",
    "\n",
    "# Use optim\n",
    "parameters = rnn.parameters()\n",
    "optimizer = torch.optim.Adam(parameters, lr = 1e-2)\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_value = []\n",
    "iteration = []\n",
    "# Train\n",
    "for epoch in range(250):\n",
    "    out,state = rnn(input,state)\n",
    "    out = out.view(seq_len, -1)\n",
    "    res =  [idx2char[x] for x in torch.argmax(out, dim=1)]\n",
    "    loss = criterion(out,target)\n",
    "    # Print result occasionally\n",
    "    if epoch%10 == 0:\n",
    "        print('epoch = ', epoch)\n",
    "        print('loss = ', loss.item())\n",
    "        print(res)\n",
    "        print('---------------------\\n')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    loss_value.append(loss)\n",
    "    iteration.append(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mapsgan)",
   "language": "python",
   "name": "mapsgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
